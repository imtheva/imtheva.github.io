<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Thevathayarajh Thayananthan </title> <meta name="author" content="Thevathayarajh Thayananthan"> <meta name="description" content="Personal website of Thevathayarajh Thayananthan — research, projects, publications, and writing on science, engineering, and space. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo-1.png?5f79aa8a9c5775ce3c181141561fab99"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://imtheva.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script async src="//cdn.plu.mx/widget-popup.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/news/">News</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/teaching/">Teaching</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/repositories/">Repositories</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/gallery/">Gallery</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/useful-links/">Useful Links</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Thevathayarajh</span> Thayananthan </h1> <p class="desc"><a href="https://sites.google.com/view/xin-zhang-lab/team" rel="external nofollow noopener" target="_blank">Graduate Research Assistant</a>. Environmental, Civil, Agriculutral and Mechanical Engineering, College of Engineering, University of Georgia</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?795a156c3561434d8cee1699755a2ccf" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>110 Riverbend RD</p> <p>Riverbend Research Lab North, 001E</p> <p>Athens, GA 30605</p> </div> </div> <div class="clearfix"> <p>I am a Graduate Research Assistant in the School of Environmental, Civil, Agricultural, and Mechanical Engineering at the University of Georgia, where I work on agricultural robotics, automation, and intelligent sensing technologies to support sustainable farming. My research combines machine vision, robotic manipulation, and real-world field experiments to create practical systems that improve farm efficiency and reduce manual labor.</p> <p>Previously, I worked as a Graduate Research Assistant in the Department of Agricultural and Biological Engineering at Mississippi State University. During this time, I developed a strong foundation in agricultural engineering, precision agriculture, and applied research methods. These experiences shaped my interest in building engineering solutions that can be tested and used in real agricultural environments.</p> <p>My research interests include autonomous field robots, computer vision, sensor-based decision systems, and robotic end-effectors for selective harvesting. I am especially interested in developing systems that are reliable in outdoor conditions and can be adopted by farmers to improve productivity and sustainability.</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Dec 16, 2025</th> <td> <a href="https://www.linkedin.com/feed/update/urn:li:activity:7406751218846441473/" target="_blank" rel="noopener"> TECH TUESDAY: Check out Thevathayarajh Thayananthan’s Design and development of an autonomous vision-guided cotton picker for selective and targeted robotic picking with Dr. Xin Zhang! </a> </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 21, 2025</th> <td> <a href="https://msstate-innovations.technologypublisher.com/technology/58899" target="_blank" rel="noopener"> Design and development of an autonomous vision-guided cotton picker for selective and targeted robotic picking - MSU OTM </a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 29, 2024</th> <td> <a href="https://farmflavor.com/mississippi/mississippi-technology/agriculture-technology-advancements-revolutionize-mississippi-ag-industry/" rel="external nofollow noopener" target="_blank">Farm Flavor: Agriculture Technology Advancements Revolutionize Mississippi Ag Industry</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 19, 2023</th> <td> <a href="https://drive.google.com/file/d/195D2IltqJIMasFkdfChXs89tpoNugnbl/view" target="_blank" rel="noopener"> MSU ABE Newsletter: Awards – Thevathayarajh Thayananthan </a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 01, 2023</th> <td> <a href="https://www.linkedin.com/embed/feed/update/urn:li:ugcPost:7124866546434281474?compact=1" target="_blank" rel="noopener"> MSU AAI: Market Day Report talks MSU’s Agricultural Autonomy Institute </a> </td> </tr> </table> </div> </div> <h2> <a href="/blog/" style="color: inherit">Latest posts</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jan 16, 2026</th> <td> <a class="news-title" href="https://medium.com/@theva1993/computer-vision-in-agricultural-engineering-0513dc142326" target="_blank" rel="external nofollow noopener">How Computer Vision Is Transforming Agricultural Engineering</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 09, 2026</th> <td> <a class="news-title" href="https://medium.com/@theva1993/from-science-fiction-to-farmland-why-robotics-and-ai-are-inevitable-in-agriculture-97c18d9d9956" target="_blank" rel="external nofollow noopener">From Science Fiction to Farmland: Why Robotics &amp; AI Are Inevitable in Agriculture</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 27, 2025</th> <td> <a class="news-title" href="/blog/2025/MSc/">MIS</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Latest publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100 venue-badge" style="--venue-color-light: #FFF7CC; --venue-color-dark: #736100;"> <div>Agricultural Robotics</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/CottonSim.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CottonSim.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="thayananthan2025cottonsimb" class="col-sm-8"> <div class="title">CottonSim: A vision-guided autonomous robotic system for cotton harvesting in Gazebo simulation</div> <div class="author"> <em>Thevathayarajh Thayananthan</em>, Xin Zhang, Yanbo Huang, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Jingdao Chen, Nuwan K Wijewardane, Vitor S Martins, Gary D Chesser, Christopher T Goodin' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Computers and Electronics in Agriculture</em>. <em>More Information</em> can be <a href="https://github.com/imtheva/CottonSim" rel="external nofollow noopener" target="_blank">found here</a> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.compag.2025.110963" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.compag.2025.110963" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a class="plumx-plum-print-popup" href="https://plu.mx/plum/a/?doi=10.1016/j.compag.2025.110963" target="_blank" rel="noopener" aria-label="PlumX metrics" style="display:inline-flex; align-items:center; margin-left:6px;"> <span class="badge bg-secondary">PlumX</span> </a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MpKhKEUAAAAJ&amp;citation_for_view=MpKhKEUAAAAJ:hqOjcs7Dif8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Cotton is a major cash crop in the United States, with the country being a leading global producer and exporter. Nearly all U.S. cotton is grown in the Cotton Belt, spanning 17 states in the southern region. Harvesting remains a critical yet challenging stage, impacted by the use of costly, environmentally harmful defoliants and heavy, expensive cotton pickers. These factors contribute to yield loss, reduced fiber quality, and soil compaction, which collectively threaten long-term sustainability. To address these issues, this study proposes a lightweight, small-scale, vision-guided autonomous robotic cotton picker as an alternative. An autonomous system, built on Clearpath’s Husky platform and integrated with the CottonEye perception system, was developed and tested in the Gazebo simulation environment. A virtual cotton field was designed to facilitate autonomous navigation testing. The navigation system used Global Positioning System (GPS) and map-based guidance, assisted by an RGBdepth camera and a YOLOv8nseg instance segmentation model. The model achieved a mean Average Precision (mAP) of 85.2%, a recall of 88.9%, and a precision of 93.0%. The GPS-based approach reached a 100% completion rate (CR) within a threshold, while the map-based method achieved a 96.7% CR within a 0.25 m threshold. The developed Robot Operating System (ROS) packages enable robust simulation of autonomous cotton picking, offering a scalable baseline for future agricultural robotics. CottonSim code and datasets are publicly available on GitHub.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100 venue-badge" style="--venue-color-light: #5CDB95; --venue-color-dark: #009f36;"> <div>Computer Vision</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/blackberry.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="blackberry.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="thayananthan2025field" class="col-sm-8"> <div class="title">In-Field Multi-Ripeness Blackberry Detection for Soft Robotic Harvesting</div> <div class="author"> <em>Thevathayarajh Thayananthan</em>, Xin Zhang, Jonathan Harjono, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Yanbo Huang, Wenbo Liu, Amanda L McWhirt, Renee T Threlfall, Yue Chen' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Journal of the ASABE</em>. <em>More Information</em> can be <a href="https://github.com/Zhanglab-abe/Multi-Ripeness_Blackberry" rel="external nofollow noopener" target="_blank">found here</a> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.13031/ja.16300" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.13031/ja.16300" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a class="plumx-plum-print-popup" href="https://plu.mx/plum/a/?doi=10.13031/ja.16300" target="_blank" rel="noopener" aria-label="PlumX metrics" style="display:inline-flex; align-items:center; margin-left:6px;"> <span class="badge bg-secondary">PlumX</span> </a> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=MpKhKEUAAAAJ&amp;citation_for_view=MpKhKEUAAAAJ:0EnyYjriUFMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Blackberry harvesting is a crucial step for the fresh market production, requiring multiple passes of hand-picking because the berries do not ripen simultaneously, even on a plant, during the harvesting season. The blackberry harvesting process encounters several major hurdles in the U.S., including the shortage of agricultural labor and postharvest fruit quality since the blackberries are highly delicate and sensitive. Developing a computer vision-enabled robotic system for selectively picking blackberries can mitigate issues and secure the profitability of fresh blackberry growers. In-field blackberry detection and localization are extremely challenging attributable to several driving factors, such as the small size of the target berries, multiple levels of berry ripeness, and great variation of outdoor lighting conditions. This study aims to assess and compare the feasibility, accuracy, and efficiency of a series of state-of-the-art YOLO (You Only Look Once) models in detecting multi-ripeness blackberries in the farm conditions. A total of 1,086 images containing three different ripeness levels of blackberries were observed during the two-year harvesting season, including ripe berries (in black color), berries in the ripening stage (in pink color), and unripe berries (in green color). The computer vision pipeline developed in this study had the ability to detect and localize all berries at different ripeness levels, while detecting the ripe berries only was a particular focus. Overall, nine YOLO models (i.e., YOLOv5-x6, YOLOv6-l6, YOLOv7-base, YOLOv7-x, YOLOv7-e6e, YOLOv8-n, YOLOv8-x, YOLOv12-n, and YOLOv12-x) were trained and validated using randomly partitioned 760 (70%) and 108 images (10%), respectively. Among these models, YOLOv7-base outperformed the others in balancing mean Average Precision (mAP) and frames-per-second (FPS) on the test set, which comprised 218 images (20%). More specifically, YOLOv7-base achieved the mAP of 91.1%, F1-score of 84.9%, and inference speed of 12.6 ms per image with 1,024 x 1,024 pixels across all classes of ripeness. In addition, its mAP on the ripe berries was 92.4%, making YOLOv7-base a reliable tool for near real-time, in-field blackberry detection for soft robotic selective harvesting.</p> </div> </div> </div> </li> </ol> </div> </article> </div> <div class="social text-center mt-5"> <div class="contact-icons"> <a href="https://imtheva.github.io/blog/" title="Blogger"><i class="fa-brands fa-blogger-b"></i></a> <a href="/cv/" title="CV" target="_blank"><i class="ai ai-cv"></i></a> <a href="mailto:%74%68%65%76%61%31%39%39%33@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/imtheva" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/imtheva" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://medium.com/@theva1993" title="Medium" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-medium"></i></a> <a href="https://orcid.org/0009-0007-2576-4348" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://www.researchgate.net/profile/Thevathayarajh-Thayananthan/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://scholar.google.com/citations?user=MpKhKEUAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note">Preferred contact via email theva@uga.edu or theva1993@gmail.com </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Thevathayarajh Thayananthan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: January 16, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>